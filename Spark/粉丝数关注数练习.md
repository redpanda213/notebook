依赖包

```xml
<dependency>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-graphx_2.11</artifactId>
    <version>2.4.3</version>
</dependency>
```



```scala
val begin = sc.textFile("file:///opt/data/twitter_graph_data.txt")
//begin: org.apache.spark.rdd.RDD[String] = file:///opt/data/twitter_graph_data.txt MapPartitionsRDD[1] at textFile at <console>:24

val vects = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");Seq((arr(0),arr(1)),(arr(2),arr(3)))})
//vects: org.apache.spark.rdd.RDD[Seq[(String, String)]] = MapPartitionsRDD[2] at map at <console>:25


vects.flatMap(e=>e).collect
//res5: Long = 3344

vects.flatMap(e=>e).distinct(6).count
//res4: Long = 98

val lines = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");(arr(0),arr(2),1)})
//lines: org.apache.spark.rdd.RDD[(String, String, Int)] = MapPartitionsRDD[13] at map at <console>:25
val lines = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");Edge(arr(0),arr(2),1)})
/*报错
<console>:28: error: type mismatch;
 found   : String
 required: org.apache.spark.graphx.VertexId
    (which expands to)  Long
       val lines = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");Edge(arr(0),arr(2),1)})
*/

```



```scala
//思考错误后，修改后的写法
//顶点vertix
val vects = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");Seq((arr(1).toLong,arr(0)),(arr(3).toLong,arr(2)))}).flatMap(e=>e).distinct(6)
//边edge
val lines = begin.map(e=>{var arr = e.replace("(","").replace(")","").split(",");Edge(arr(1).toLong,arr(3).toLong,1)})


```

```scala
//图
val graph = Graph(vects,lines)
//graph: org.apache.spark.graphx.Graph[String,Int] = org.apache.spark.graphx.impl.GraphImpl@31ab743f

```

```scala
graph.mapVetices.outerJoinGraph()
```

